{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "sentences = word2vec.LineSentence('data3.txt')\n",
    "path = get_tmpfile(\"w2v_model2.bin\") #创建临时文件\n",
    "spmodel = Word2Vec(sentences, size=100, window=10,sg=1, min_count=1,workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('cbgonganmodel.bin',binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('怨声载道', 0.9837099313735962)\n",
      "('美好', 0.9834924340248108)\n",
      "('真心', 0.9834119081497192)\n",
      "('生命财产', 0.9821381568908691)\n",
      "('严加', 0.9808769822120667)\n",
      "('传染病', 0.9805291295051575)\n",
      "('易有', 0.980425238609314)\n",
      "('生命安全', 0.9798831939697266)\n",
      "('劝说', 0.9785289764404297)\n",
      "('求', 0.9779046773910522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for key in spmodel.similar_by_word('爆炸', topn =10):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.27665943, -0.3183454 ,  0.37644538,  0.1313346 , -0.12299901,\n",
       "        0.13735959, -0.0904852 ,  0.1483036 ,  0.23479797, -0.0380918 ,\n",
       "        0.162834  ,  0.1529374 ,  0.10948602,  0.1225908 ,  0.14507079,\n",
       "        0.23567413,  0.26785523, -0.07244071, -0.41427478,  0.03704834,\n",
       "       -0.11803831, -0.0989292 ,  0.08342316,  0.02250017, -0.03648548,\n",
       "        0.08160986, -0.0076189 ,  0.02600959,  0.21826741,  0.03566729,\n",
       "       -0.16359176,  0.0339879 , -0.26034451,  0.15123361,  0.27822307,\n",
       "        0.13392808,  0.07012361, -0.44978499, -0.09577505,  0.07963108,\n",
       "       -0.21628796,  0.00463233, -0.10124639, -0.1191857 ,  0.21636309,\n",
       "        0.12522632, -0.17867105, -0.34192839, -0.02541428,  0.47974166,\n",
       "       -0.14490943, -0.28721717,  0.04146675,  0.15614368, -0.32490167,\n",
       "        0.10309174,  0.28783923, -0.129095  , -0.15074062,  0.08483274,\n",
       "        0.13096677,  0.24493404, -0.02492385,  0.15508035, -0.07268898,\n",
       "       -0.05231657,  0.27173433,  0.0274427 , -0.11129036, -0.22255333,\n",
       "       -0.1417077 , -0.15633106, -0.07570169, -0.04836036, -0.18091796,\n",
       "        0.08799481, -0.09890397, -0.07859734, -0.32832867,  0.02054533,\n",
       "       -0.45480469, -0.29065663,  0.25770202,  0.13467646,  0.07052849,\n",
       "       -0.18560632,  0.03067173,  0.36463496, -0.0298362 ,  0.04745517,\n",
       "        0.11996412,  0.04742427,  0.1614286 ,  0.06094858,  0.32751751,\n",
       "        0.13488729, -0.21349171,  0.22172992, -0.15146339, -0.09934536], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spmodel[\"爆炸\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\mazheng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.763 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "df = pd.read_csv('wenben.csv')\n",
    "X = df[['xinxi']]\n",
    "X['cutted_xinxi'] = X.xinxi.apply(chinese_word_cut)\n",
    "\n",
    "\n",
    "Y = open('1.1.txt',encoding = 'UTF-8-sig').read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X[[\"cutted_xinxi\"]]\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 128\n",
    "TEST_SPLIT = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train is (1095, 100)\n",
      "the shape of train is (366, 100)\n"
     ]
    }
   ],
   "source": [
    "def buildWordVector(text, size):\n",
    "    '''\n",
    "        利用函数获得每个文本中所有词向量的平均值来表征该特征向量。\n",
    "    '''\n",
    "    vec = np.zeros(100).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += spmodel[word].reshape((1, 100))\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "    \n",
    "'''获取需要所有文档的词向量，并且标准化出来'''\n",
    "x_train1 = np.concatenate([buildWordVector(x, 100) for x in X_train.cutted_xinxi])\n",
    "print (\"the shape of train is \"+repr(x_train1.shape) ) \n",
    "x_train = scale(x_train1)\n",
    "x_test1 = np.concatenate([buildWordVector(x, 100) for x in X_test.cutted_xinxi])\n",
    "print (\"the shape of train is \"+repr(x_test1.shape) ) \n",
    "x_test = scale(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69395982, -0.03021795,  0.54635503, ..., -0.03393326,\n",
       "         0.31121575, -1.3627295 ],\n",
       "       [ 1.27435321,  0.12839862,  0.26471933, ..., -1.31025565,\n",
       "        -0.03908937,  0.46256896],\n",
       "       [ 0.13808423, -0.25770024, -0.27594626, ..., -1.09128773,\n",
       "        -1.49541627, -1.19335468],\n",
       "       ..., \n",
       "       [ 0.98337782, -0.20110153,  0.24454054, ..., -1.08463818,\n",
       "        -1.15794769,  0.72350641],\n",
       "       [ 1.09426075,  0.60606594,  1.98410402, ..., -1.65209673,\n",
       "        -0.46286146,  0.95782314],\n",
       "       [ 0.74079144,  0.49867351, -0.9844574 , ...,  0.45899866,\n",
       "         0.15928014, -0.91666438]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.7786885245901639\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()  \n",
    "clf.fit(x_train, y_train);  \n",
    "preds = clf.predict(x_test);\n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.8852459016393442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC   \n",
    "svclf = SVC(kernel = 'linear') \n",
    "svclf.fit(x_train,y_train)  \n",
    "predss = svclf.predict(x_test);  \n",
    "num = 0\n",
    "predss = predss.tolist()\n",
    "for i,pred in enumerate(predss):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(predss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.8743169398907104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "clf = KNeighborsClassifier()  \n",
    "clf.fit(x_train, y_train);  \n",
    "preds = clf.predict(x_test);\n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[324,   0],\n",
       "       [ 42,   0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test, predss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P=324/366\n",
    "Z=324/(324+41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852459016393442"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876712328767123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8864569083447333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*P*Z)/(P+Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
