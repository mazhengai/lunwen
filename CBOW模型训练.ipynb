{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "sentences = word2vec.LineSentence('Tencent_news_Result.txt')\n",
    "path = get_tmpfile(\"w2v_model.bin\") #创建临时文件\n",
    "cbmodel = Word2Vec(sentences, size=100, window=5, min_count=1, iter=10 ,workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('cbgonganmodel.bin',binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('极易', 0.9935521483421326)\n",
      "('困难', 0.9934874773025513)\n",
      "('过路', 0.9931451082229614)\n",
      "('车辆通行', 0.9927283525466919)\n",
      "('无法', 0.9927146434783936)\n",
      "('太', 0.9925479888916016)\n",
      "('信号灯', 0.9923542141914368)\n",
      "('同时', 0.992228090763092)\n",
      "('及', 0.9920909404754639)\n",
      "('受到', 0.9918867349624634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for key in cbmodel.similar_by_word('爆炸', topn =10):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00844468, -0.01960895,  0.01672795, -0.0261167 ,  0.00509361,\n",
       "       -0.02561911,  0.01675329,  0.0038734 ,  0.04909154,  0.00857049,\n",
       "        0.07442446, -0.1116773 ,  0.04822423, -0.0556086 , -0.00657536,\n",
       "        0.03657444, -0.05326466,  0.01157148, -0.01422363,  0.00541145,\n",
       "        0.00346457,  0.02509604, -0.0187537 ,  0.02655778, -0.02183228,\n",
       "        0.05193711, -0.08002175, -0.01257197, -0.02308513,  0.00139855,\n",
       "        0.0482249 , -0.00153102, -0.01204232, -0.08629581,  0.0248101 ,\n",
       "       -0.01722659, -0.04806007, -0.0023226 ,  0.04780351,  0.00366191,\n",
       "        0.00460518,  0.01596103,  0.02035832, -0.0822442 , -0.02424444,\n",
       "        0.00134193,  0.06490051, -0.04053535, -0.0225993 ,  0.01513438,\n",
       "        0.00410855, -0.04871228,  0.02484216,  0.02018281, -0.05631958,\n",
       "        0.04296947,  0.05393486, -0.02370854, -0.00843136,  0.0137609 ,\n",
       "        0.01090148, -0.02636641, -0.03545165,  0.04489356, -0.00677312,\n",
       "       -0.01805393,  0.01714433, -0.05667847, -0.0302602 ,  0.01115119,\n",
       "        0.03373282, -0.01328254, -0.00612369,  0.01355338,  0.0388792 ,\n",
       "        0.03331893,  0.01546787, -0.01210619, -0.00748636,  0.02317216,\n",
       "       -0.03149065, -0.00405403, -0.06228137,  0.00290154, -0.01228938,\n",
       "       -0.05229692, -0.03890819, -0.04125505,  0.02373485,  0.00651349,\n",
       "       -0.01223815, -0.03496448,  0.01705788,  0.0637432 ,  0.03678839,\n",
       "        0.02374786, -0.05770564, -0.00668479, -0.00886414,  0.02200775], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbmodel[\"爆炸\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "df = pd.read_csv('wenben.csv')\n",
    "X = df[['xinxi']]\n",
    "X['cutted_xinxi'] = X.xinxi.apply(chinese_word_cut)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y = open('1.1.txt',encoding = 'UTF-8-sig').read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X[[\"cutted_xinxi\"]]\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import gensim\n",
    "VECTOR_DIR = 'vectors.bin'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 128\n",
    "TEST_SPLIT = 0.2\n",
    "CBmodel2 = gensim.models.KeyedVectors.load_word2vec_format(VECTOR_DIR, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train is (1095, 100)\n",
      "the shape of train is (366, 100)\n"
     ]
    }
   ],
   "source": [
    "def buildWordVector(text, size):\n",
    "    '''\n",
    "        利用函数获得每个文本中所有词向量的平均值来表征该特征向量。\n",
    "    '''\n",
    "    vec = np.zeros(100).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += cbmodel[word].reshape((1, 100))\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "    \n",
    "'''获取需要所有文档的词向量，并且标准化出来'''\n",
    "x_train1 = np.concatenate([buildWordVector(x, 100) for x in X_train.cutted_xinxi])\n",
    "print (\"the shape of train is \"+repr(x_train1.shape) ) \n",
    "x_train = scale(x_train1)\n",
    "x_test1 = np.concatenate([buildWordVector(x, 100) for x in X_test.cutted_xinxi])\n",
    "print (\"the shape of train is \"+repr(x_test1.shape) ) \n",
    "x_test = scale(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93481705, -1.27952796,  1.21519861, ...,  0.31532867,\n",
       "        -2.0523159 ,  1.27775492],\n",
       "       [-0.03026029,  2.49586811, -2.42984166, ...,  1.28701296,\n",
       "         1.1127782 , -0.9396904 ],\n",
       "       [ 0.68406502, -1.10243218,  1.07443682, ..., -0.72182135,\n",
       "        -0.98560868, -0.02987566],\n",
       "       ..., \n",
       "       [-0.84487802,  1.5978637 , -1.49684738, ...,  1.52852354,\n",
       "         0.30026652, -0.03844758],\n",
       "       [ 0.05666303,  0.58060373, -0.54487036, ..., -0.71117582,\n",
       "         1.08112828, -0.03369656],\n",
       "       [-0.35405733, -0.71637541,  0.94388109, ..., -0.58223909,\n",
       "        -1.10551235,  0.8197568 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.6120218579234973\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()  \n",
    "clf.fit(x_train, y_train);  \n",
    "preds = clf.predict(x_test);\n",
    "num = 0\n",
    "preds = preds.tolist()\n",
    "for i,pred in enumerate(preds):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.8879781420765027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC   \n",
    "svclf = SVC(kernel = 'linear') \n",
    "svclf.fit(x_train,y_train)  \n",
    "predss = svclf.predict(x_test);  \n",
    "num = 0\n",
    "predss = predss.tolist()\n",
    "for i,pred in enumerate(predss):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:0.8770491803278688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "clf = KNeighborsClassifier()  \n",
    "clf.fit(x_train, y_train);  \n",
    "predsss = clf.predict(x_test);\n",
    "num = 0\n",
    "predsss = predsss.tolist()\n",
    "for i,pred in enumerate(predsss):\n",
    "    if int(pred) == int(y_test[i]):\n",
    "        num += 1\n",
    "print ('precision_score:' + str(float(num) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[320,   4],\n",
       "       [ 41,   1]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test, predsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877049180328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:459: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test,predsss,labels=[1,0],average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488429880416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:459: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test,predsss,labels=[1,0],average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
